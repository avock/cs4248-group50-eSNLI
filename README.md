## BERT for Natural Language Inference on e-SNLI Dataset
#### CS4248 Group 50 Project Code Repository

This project explores the application of the BERT (Bidirectional Encoder Representations from Transformers) model to the [e-SNLI dataset](https://github.com/OanaMariaCamburu/e-SNLI), aiming to understand its state-of-the-art performance in natural language inference tasks. The focus is on dissecting BERT's architecture and its interplay with semantic complexity to demystify the "black-box" nature of such models.

## Repository Overview
This repository contais code files and notebooks used for various tasks including data analysis, data pre-processing, model training and model evaluation. Here is a brief overview of the repository's structure: //TODO

## Installation
//TODO

## Getting Started 
//TODO

### License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Acknowledgments
- Dataset provided by [e-SNLI Dataset](https://github.com/OanaMariaCamburu/e-SNLI).
- We'd like to thank Ms. Esther Gan as well as Prof. Kan Min-Yen and Prof. Christian Von Der Weth for their guidance throughout this project as well as the course throughout the semester.