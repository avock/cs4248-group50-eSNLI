{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IbY2z4SHKsXQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time, datetime, numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymQAp6XHEqzs"
      },
      "source": [
        "## Mounting Google Drive to Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-a7linJK1NI",
        "outputId": "211ca4bd-6aff-4c72-d682-955bb8758c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/[CS4248] Project Folder/data/esnli_train.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/[CS4248] Project Folder/data/esnli_val.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/[CS4248] Project Folder/data/esnli_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjchJ6V9qYSS"
      },
      "source": [
        "## Corpus Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVeIoPxQqdI9"
      },
      "source": [
        "#### Analaysis Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUkB6DhPqY-a",
        "outputId": "25e282d1-eefd-4b82-b8f6-ec7cee9d0608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistics for DataFrame: df\n",
            "Column: Sentence1\n",
            "Word Count Statistics:\n",
            "  Average: 12.81492236508602\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 5.673234137256183\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 11.89091111888892\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 4.594794723883672\n",
            "  Vocabulary Size: 23894\n",
            "  Normalized Vocabulary Size: 0.09190035346289793\n",
            "\n",
            "Column: Sentence2\n",
            "Word Count Statistics:\n",
            "  Average: 7.398163817904891\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 3.049651862169359\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 7.243938368282589\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 2.8062685308215864\n",
            "  Vocabulary Size: 36777\n",
            "  Normalized Vocabulary Size: 0.14145217618732595\n",
            "\n",
            "Column: Explanation_1\n",
            "Word Count Statistics:\n",
            "  Average: 12.698958024824318\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 6.453918558510613\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 11.507983091462265\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 5.037312336567891\n",
            "  Vocabulary Size: 57706\n",
            "  Normalized Vocabulary Size: 0.22195725170873928\n",
            "\n",
            "Statistics for DataFrame: val\n",
            "Column: Sentence1\n",
            "Word Count Statistics:\n",
            "  Average: 13.938325543588702\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.315918895787601\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.79892298313351\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 5.0545396548143895\n",
            "  Vocabulary Size: 5569\n",
            "  Normalized Vocabulary Size: 0.5658402763665922\n",
            "\n",
            "Column: Sentence2\n",
            "Word Count Statistics:\n",
            "  Average: 7.510668563300142\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 3.1342543086371397\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 7.34911603332656\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 2.8703693579247647\n",
            "  Vocabulary Size: 6838\n",
            "  Normalized Vocabulary Size: 0.6947774842511685\n",
            "\n",
            "Column: Explanation_1\n",
            "Word Count Statistics:\n",
            "  Average: 12.93019711440764\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.162361956169531\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 11.764986791302581\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 4.8657595687086586\n",
            "  Vocabulary Size: 10386\n",
            "  Normalized Vocabulary Size: 1.055273318431213\n",
            "\n",
            "Column: Explanation_2\n",
            "Word Count Statistics:\n",
            "  Average: 13.804714488925015\n",
            "  Median: 13.0\n",
            "  Standard Deviation: 6.518139861290382\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.423694371062792\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 5.096759297991727\n",
            "  Vocabulary Size: 11193\n",
            "  Normalized Vocabulary Size: 1.1372688477951636\n",
            "\n",
            "Column: Explanation_3\n",
            "Word Count Statistics:\n",
            "  Average: 13.510363747205853\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.896507888965767\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.174659622028043\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 5.3538929663675034\n",
            "  Vocabulary Size: 10560\n",
            "  Normalized Vocabulary Size: 1.0729526519000203\n",
            "\n",
            "Statistics for DataFrame: test\n",
            "Column: Sentence1\n",
            "Word Count Statistics:\n",
            "  Average: 13.909507328990228\n",
            "  Median: 13.0\n",
            "  Standard Deviation: 6.177466340859692\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.791530944625407\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 5.0070090874179\n",
            "  Vocabulary Size: 5549\n",
            "  Normalized Vocabulary Size: 0.5648412052117264\n",
            "\n",
            "Column: Sentence2\n",
            "Word Count Statistics:\n",
            "  Average: 7.4822882736156355\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 3.080074765626552\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 7.322271986970684\n",
            "  Median: 7.0\n",
            "  Standard Deviation: 2.8300405236961717\n",
            "  Vocabulary Size: 7009\n",
            "  Normalized Vocabulary Size: 0.7134568403908795\n",
            "\n",
            "Column: Explanation_1\n",
            "Word Count Statistics:\n",
            "  Average: 12.989311889250814\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.4983701739269275\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 11.785728827361563\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 5.036248482415087\n",
            "  Vocabulary Size: 10646\n",
            "  Normalized Vocabulary Size: 1.083672638436482\n",
            "\n",
            "Column: Explanation_2\n",
            "Word Count Statistics:\n",
            "  Average: 13.500101791530945\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.411766462941881\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.161848534201955\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 4.96097002800379\n",
            "  Vocabulary Size: 10919\n",
            "  Normalized Vocabulary Size: 1.111461726384365\n",
            "\n",
            "Column: Explanation_3\n",
            "Word Count Statistics:\n",
            "  Average: 13.348025244299674\n",
            "  Median: 12.0\n",
            "  Standard Deviation: 6.909983554901156\n",
            "Vocabulary Count Statistics:\n",
            "  Average: 12.04600977198697\n",
            "  Median: 11.0\n",
            "  Standard Deviation: 5.23142366133106\n",
            "  Vocabulary Size: 10593\n",
            "  Normalized Vocabulary Size: 1.078277687296417\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_word_statistics(df, col_name):\n",
        "  column = df[col_name].dropna()\n",
        "  word_counts = column.apply(lambda x: len(x.split()))\n",
        "\n",
        "  results = {\n",
        "      \"avg_word_count\": np.mean(word_counts),\n",
        "      \"median_word_count\": np.median(word_counts),\n",
        "      \"std_dev_word_count\": np.std(word_counts)\n",
        "  }\n",
        "\n",
        "  return results\n",
        "\n",
        "def get_unqiue_vocabs(df, col_name):\n",
        "  column = df[col_name].dropna()\n",
        "  vocab_set = set()\n",
        "  for sentence in column:\n",
        "    vocab_set.update(sentence.split())\n",
        "\n",
        "  return vocab_set\n",
        "\n",
        "def get_vocab_statistics(df, col_name):\n",
        "  column = df[col_name].dropna()\n",
        "  vocab_counts = column.apply(lambda x: len(set(x.split())))\n",
        "\n",
        "  results = {\n",
        "      \"avg_vocab_count\": np.mean(vocab_counts),\n",
        "      \"median_vocab_count\": np.median(vocab_counts),\n",
        "      \"std_dev_vocab_count\": np.std(vocab_counts),\n",
        "      \"vocab_size\": len(get_unqiue_vocabs(df, col_name)),\n",
        "      \"normalized_vocab_size\": len(get_unqiue_vocabs(df, col_name))/len(column)\n",
        "  }\n",
        "\n",
        "  return results\n",
        "\n",
        "def print_statistics(df, df_name, target_cols):\n",
        "    print(f\"Statistics for DataFrame: {df_name}\")\n",
        "    for col_name in target_cols:\n",
        "        print(f\"Column: {col_name}\")\n",
        "        word_stats = get_word_statistics(df, col_name)\n",
        "        vocab_stats = get_vocab_statistics(df, col_name)\n",
        "        print(\"Word Count Statistics:\")\n",
        "        print(\"  Average:\", word_stats[\"avg_word_count\"])\n",
        "        print(\"  Median:\", word_stats[\"median_word_count\"])\n",
        "        print(\"  Standard Deviation:\", word_stats[\"std_dev_word_count\"])\n",
        "        print(\"Vocabulary Count Statistics:\")\n",
        "        print(\"  Average:\", vocab_stats[\"avg_vocab_count\"])\n",
        "        print(\"  Median:\", vocab_stats[\"median_vocab_count\"])\n",
        "        print(\"  Standard Deviation:\", vocab_stats[\"std_dev_vocab_count\"])\n",
        "        print(\"  Vocabulary Size:\", vocab_stats[\"vocab_size\"])\n",
        "        print(\"  Normalized Vocabulary Size:\", vocab_stats[\"normalized_vocab_size\"])\n",
        "        print()\n",
        "\n",
        "print_statistics(df, \"df\", ['Sentence1', 'Sentence2', 'Explanation_1'])\n",
        "print_statistics(val, \"val\", ['Sentence1', 'Sentence2', 'Explanation_1', 'Explanation_2', 'Explanation_3'])\n",
        "print_statistics(test, \"test\", ['Sentence1', 'Sentence2', 'Explanation_1', 'Explanation_2', 'Explanation_3'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TbRBVfeMFF23",
        "bm7iYsexFrUm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
