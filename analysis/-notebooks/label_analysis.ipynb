{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UUrppHh7nw1",
        "outputId": "d22dd0fc-9e8d-454a-cbc5-a6d4f674b3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/CS4248/dataset/esnli_train_1.csv')\n",
        "df1 = df[['Sentence1', 'Sentence2', 'gold_label']]\n",
        "df.dropna\n",
        "test = pd.read_csv('/content/drive/MyDrive/CS4248/dataset/esnli_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df[['Explanation_1', 'gold_label']]\n",
        "negation_list = ['not', 'cannot', 'never']\n",
        "def count_negations(row):\n",
        "  total = 0\n",
        "  if pd.isna(row['Explanation_1']):\n",
        "        return 0\n",
        "  for word in row['Explanation_1'].split():\n",
        "    if word.lower() in negation_list:\n",
        "      total += 1\n",
        "  return total\n",
        "\n",
        "df2['negations'] = df2.apply(count_negations, axis=1)\n",
        "average_negations = df2.groupby('gold_label')[['negations']].mean()\n",
        "print(average_negations)\n",
        "\n",
        "def count_not_necessary(row):\n",
        "  if pd.isna(row['Explanation_1']):\n",
        "        return 0\n",
        "  total = 0\n",
        "  if 'not necessarily' in row['Explanation_1']:\n",
        "    return 1\n",
        "  return total\n",
        "\n",
        "df2['not_necessary'] = df2.apply(count_not_necessary, axis=1)\n",
        "average_not_necessary = df2.groupby('gold_label')[['not_necessary']].mean()\n",
        "print(average_not_necessary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAUInUMrEsU4",
        "outputId": "74325143-3e14-4b28-ae9a-664792c9488f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-37165c399716>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['negations'] = df2.apply(count_negations, axis=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               negations\n",
            "gold_label              \n",
            "contradiction   0.613195\n",
            "entailment      0.014958\n",
            "neutral         0.748401\n",
            "               not_necessary\n",
            "gold_label                  \n",
            "contradiction       0.002111\n",
            "entailment          0.000092\n",
            "neutral             0.098734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-37165c399716>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['not_necessary'] = df2.apply(count_not_necessary, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 way\n",
        "df4 = df[['Sentence1', 'Sentence2', 'Explanation_1', 'gold_label']]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def count_similar_words(row, c1, c2, c3):\n",
        "  if pd.isna(row[c1]) or pd.isna(row[c2]) or pd.isna(row[c3]):\n",
        "        return 0\n",
        "  s1 = set(row[c1].split())\n",
        "  s2 = set(row[c2].split())\n",
        "  s3 = set(row[c3].split())\n",
        "  s1 = set(word.lower() for word in row[c1].split() if word.lower() not in stop_words)\n",
        "  s2 = set(word.lower() for word in row[c2].split() if word.lower() not in stop_words)\n",
        "  s3 = set(word.lower() for word in row[c3].split() if word.lower() not in stop_words)\n",
        "  return len(s1 & s2 & s3)\n",
        "\n",
        "\n",
        "df4['count'] = df4.apply(count_similar_words, args=('Sentence1', 'Sentence2', 'Explanation_1'), axis=1)\n",
        "average_count = df4.groupby('gold_label')[['count']].mean()\n",
        "print(average_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPo_5I_IRQ88",
        "outputId": "7fa31ca1-1c17-4010-93dc-640d242c124d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  count\n",
            "gold_label             \n",
            "contradiction  0.468113\n",
            "entailment     0.871318\n",
            "neutral        0.724545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f1a2819191ae>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df4['count'] = df4.apply(count_similar_words, args=('Sentence1', 'Sentence2', 'Explanation_1'), axis=1)\n"
          ]
        }
      ]
    }
  ]
}